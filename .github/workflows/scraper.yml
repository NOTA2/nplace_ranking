# This workflow will do a clean installation of node dependencies, cache/restore them, build the source code and run tests across different versions of node
# For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-nodejs

name: Run Scraper - Update data # 워크플로우 이름 지정

on:
  workflow_dispatch:
  schedule:
    - cron: "0 */4 * * *" # 주기적으로 실행하기 위한 스케줄링 - cron 설정

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        node-version: [20.x]
        # See supported Node.js release schedule at https://nodejs.org/en/about/releases/
    steps:
    - uses: actions/checkout@v4
    - name: Use Node.js ${{ matrix.node-version }}
      uses: actions/setup-node@v3
      with:
        node-version: ${{ matrix.node-version }}
        cache: 'npm'
    - run: npm ci
    - run: npm run build --if-present
    - name: Run Scraper with node
      run: |
        node scrape.js
      env:
        GOOGLE_PRIVATE_KEY : ${{ secrets.GOOGLE_PRIVATE_KEY }}
        GOOGLE_SERVICE_ACCOUNT_EMAIL : ${{ secrets.GOOGLE_SERVICE_ACCOUNT_EMAIL }}
    - name: Commits
      run: |
        git config --local user.email "skaska121212@gmail.com"
        git config --local user.name "Auto_Scraping_Name" # 커밋에 포함될 이름
        git add .
        git commit -m "Auto - Update data with Scraping" # 커밋 메세지
    - name: Push
      uses: ad-m/github-push-action@master
      with:
        branch: 'master'
        github_token: ${{ secrets.GH_TOKEN }}
